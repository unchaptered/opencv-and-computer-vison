{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ,   0.     ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645,   0.     ],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ,   1.     ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ,   1.     ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ,   1.     ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data = genfromtxt(\n",
    "    '../../DATA/bank_note_data.txt',\n",
    "    delimiter=','                     # 기본 특징점들을 콤마(,)를 기준으로 분할\n",
    ")\n",
    "real_data\n",
    "# [[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699,   0.     ]]\n",
    "#     feature,   feature,  feature,   feature,    label - 0 means fake paper money\n",
    "#                                                       - 1 means real paper money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = real_data[:,4]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
       "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
       "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
       "       ...,\n",
       "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
       "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
       "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = real_data[:, :4]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features    # 대문자 X는 일반적으로 2D 행렬 의미\n",
    "y = labels      # 소문자 Y는 단일 행렬 백터 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#########################################################################\n",
    "## `특징점들`을 레이블들을 훈련용과 테스트 세트로 분류해주는 라이브러리 ##\n",
    "## 이 라이브러리는 자동으로 정렬을 해줘서 레이블들이 섞이지 않도록 제어 ##\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "##########################################################################################################################\n",
    "## test_size에 할당된 0.33(33%)에 해당하는 숫자만큼의 특징점들은 X_test가 되고 그 숫자만큼의 레이블들은 y_test가 됩니다.  ##\n",
    "## `항상 동일한 순서`로 무작위 정렬되기 위한 시드값으로써 random_state에 42를 할당해줍니다.                               ##\n",
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 453 1372\n",
      "919 453 1372\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(X))\n",
    "print(len(y_train), len(y_test), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.1116 -13.2869\n"
     ]
    }
   ],
   "source": [
    "print(X_test.max(), X_test.min())\n",
    "\n",
    "#########################################################################################################\n",
    "## 만약, 최댓값이 100만 정도에 최솟값이 -13 정도라면 특징점이 몇 배 이상 벗어난 것이라고 할 수 있습니다. ##\n",
    "## 따라서, 꼭 최댓값과 최솟값을 확인하는 습관을 길러야 합니다.                                           ##\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "################################################################################################\n",
    "## 모든 특징점 데이터들이 특정 범위로 좁혀지게 되어서 Neural Network 분석을 하기 용이해지니다. ##\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_object = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_object.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scalar_object.transform(X_train)\n",
    "scaled_X_test = scalar_object.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002 0.0\n",
      "1.02679563427227 -0.0010694864308909147\n"
     ]
    }
   ],
   "source": [
    "print(scaled_X_train.max(), scaled_X_train.min())\n",
    "print(scaled_X_test.max(), scaled_X_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, input_dim=4, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 0.6776 - acc: 0.5495\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6662 - acc: 0.5495\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6567 - acc: 0.5495\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6479 - acc: 0.5495\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6356 - acc: 0.5658\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6205 - acc: 0.5974\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6055 - acc: 0.6561\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.5898 - acc: 0.7280\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.5725 - acc: 0.7639\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.5545 - acc: 0.7780\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.5355 - acc: 0.8172\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.5152 - acc: 0.8292\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.4953 - acc: 0.8368\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.4758 - acc: 0.8433\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.4573 - acc: 0.8466\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.4396 - acc: 0.8596\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.4236 - acc: 0.8672\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.4090 - acc: 0.8694\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.3958 - acc: 0.8727\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.3833 - acc: 0.8749\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.3720 - acc: 0.8781\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.3618 - acc: 0.8760\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3521 - acc: 0.8814\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3427 - acc: 0.8825\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.3345 - acc: 0.8868\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.3260 - acc: 0.8901\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.3188 - acc: 0.8901\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.3121 - acc: 0.8945\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.3047 - acc: 0.8945\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.2977 - acc: 0.8923\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.2918 - acc: 0.8977\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.2855 - acc: 0.9042\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.2794 - acc: 0.9021\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.2745 - acc: 0.9053\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.2682 - acc: 0.9119\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.2625 - acc: 0.9119\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.2573 - acc: 0.9140\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.2520 - acc: 0.9184\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.2467 - acc: 0.9184\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.2420 - acc: 0.9282\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.2370 - acc: 0.9238\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.2322 - acc: 0.9347\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.2282 - acc: 0.9282\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.2235 - acc: 0.9282\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.2190 - acc: 0.9293\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.2145 - acc: 0.9314\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.2108 - acc: 0.9380\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.2071 - acc: 0.9325\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.2025 - acc: 0.9402\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.1983 - acc: 0.9434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259fcf83e48>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[252,   5],\n",
       "       [ 22, 174]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.98      0.95       257\n",
      "        1.0       0.97      0.89      0.93       196\n",
      "\n",
      "avg / total       0.94      0.94      0.94       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model\n",
    "model.save('mysupermodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Model\n",
    "from keras.models import load_model\n",
    "\n",
    "new_model = load_model('mysupermodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
